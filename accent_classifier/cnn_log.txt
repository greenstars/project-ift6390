def modelConstruct():
    model = Sequential()
    
    ###### conv layer 1 ######
    model.add(Conv2D(32, kernel_size=(3,3), input_shape=(201, 66,1),
                     kernel_initializer=keras.initializers.glorot_normal(),activation = 'tanh'))

    keras.layers.BatchNormalization(axis = 0)
    model.add(MaxPooling2D(pool_size=(4,4), padding='SAME'))

    
    ###### conv 2 ##########
    model.add(Conv2D(32, kernel_size=(3,3), 
                                     kernel_initializer=keras.initializers.glorot_normal(seed=None),activation = 'tanh'))
    keras.layers.BatchNormalization(axis = 0)
    model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))

    
    ###### conv 3 ##########
    model.add(Conv2D(32, kernel_size=(3,3),strides=(1, 1), padding='SAME', 
                                     kernel_initializer=keras.initializers.glorot_normal(seed=None),activation = 'tanh'))

    #model.add(LeakyReLU(alpha=0.1))
    keras.layers.BatchNormalization(axis = 0)
    model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))
    
    ###### conv 4 ##########
    model.add(Conv2D(32, kernel_size=(3,3),strides=(1, 1), padding='SAME', 
                                     kernel_initializer=keras.initializers.glorot_normal(seed=None),activation = 'tanh'))

    #model.add(LeakyReLU(alpha=0.1))
    keras.layers.BatchNormalization(axis = 0)
    model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))
    
    ### Fully connected #######
    model.add(Flatten())
    #model.add(Dense(10, activation='relu'))
    #model.add(Dense(64, activation=''relu'))

    model.add(keras.layers.Dropout(0.2, noise_shape=None, seed=None))
    model.add(Dense(2, activation='softmax'))
    
    # compile and return 
    model.compile(loss=keras.losses.categorical_crossentropy,
                  optimizer=keras.optimizers.RMSprop(lr = 0.001),
                  metrics=['accuracy'])
    return model

Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 199, 64, 32)       320       
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 50, 16, 32)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 48, 14, 32)        9248      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 24, 7, 32)         0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 24, 7, 32)         9248      
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 12, 4, 32)         0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 12, 4, 32)         9248      
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 6, 2, 32)          0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 384)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 384)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 770       
=================================================================
Total params: 28,834
Trainable params: 28,834
Non-trainable params: 0
_________________________________________________________________
training on pickle x_train_splitted0.pickle
Train on 6795 samples, validate on 756 samples
Epoch 1/10
6795/6795 [==============================] - 4s 618us/step - loss: 0.6522 - acc: 0.6250 - val_loss: 0.5469 - val_acc: 0.7222
Epoch 2/10
6795/6795 [==============================] - 3s 481us/step - loss: 0.4965 - acc: 0.7582 - val_loss: 0.4428 - val_acc: 0.8003
Epoch 3/10
6795/6795 [==============================] - 3s 478us/step - loss: 0.4192 - acc: 0.8054 - val_loss: 0.4097 - val_acc: 0.8029
Epoch 4/10
6795/6795 [==============================] - 3s 476us/step - loss: 0.3698 - acc: 0.8346 - val_loss: 0.3417 - val_acc: 0.8479
Epoch 5/10
6795/6795 [==============================] - 3s 477us/step - loss: 0.3209 - acc: 0.8636 - val_loss: 0.3211 - val_acc: 0.8519
Epoch 6/10
6795/6795 [==============================] - 3s 476us/step - loss: 0.2734 - acc: 0.8871 - val_loss: 0.3074 - val_acc: 0.8704
Epoch 7/10
6795/6795 [==============================] - 3s 472us/step - loss: 0.2401 - acc: 0.9026 - val_loss: 0.2840 - val_acc: 0.8743
Epoch 8/10
6795/6795 [==============================] - 3s 474us/step - loss: 0.2128 - acc: 0.9170 - val_loss: 0.3602 - val_acc: 0.8426
Epoch 9/10
6795/6795 [==============================] - 3s 473us/step - loss: 0.1797 - acc: 0.9317 - val_loss: 0.2830 - val_acc: 0.8730
Epoch 10/10
6795/6795 [==============================] - 3s 471us/step - loss: 0.1555 - acc: 0.9386 - val_loss: 0.2380 - val_acc: 0.9021
training on pickle x_train_splitted1.pickle
Train on 6795 samples, validate on 756 samples
Epoch 1/10
6795/6795 [==============================] - 3s 474us/step - loss: 0.3663 - acc: 0.8540 - val_loss: 0.3512 - val_acc: 0.8505
Epoch 2/10
6795/6795 [==============================] - 3s 473us/step - loss: 0.2891 - acc: 0.8858 - val_loss: 0.3340 - val_acc: 0.8690
Epoch 3/10
6795/6795 [==============================] - 3s 481us/step - loss: 0.2306 - acc: 0.9096 - val_loss: 0.3105 - val_acc: 0.8796
Epoch 4/10
6795/6795 [==============================] - 3s 476us/step - loss: 0.1956 - acc: 0.9216 - val_loss: 0.2661 - val_acc: 0.8981
Epoch 5/10
6795/6795 [==============================] - 3s 483us/step - loss: 0.1698 - acc: 0.9336 - val_loss: 0.3097 - val_acc: 0.8810
Epoch 6/10
6795/6795 [==============================] - 3s 480us/step - loss: 0.1438 - acc: 0.9423 - val_loss: 0.2900 - val_acc: 0.8902
Epoch 7/10
6795/6795 [==============================] - 3s 481us/step - loss: 0.1222 - acc: 0.9535 - val_loss: 0.3492 - val_acc: 0.8690
Epoch 8/10
6795/6795 [==============================] - 3s 487us/step - loss: 0.1107 - acc: 0.9554 - val_loss: 0.3021 - val_acc: 0.9048
Epoch 9/10
6795/6795 [==============================] - 3s 486us/step - loss: 0.0991 - acc: 0.9611 - val_loss: 0.3139 - val_acc: 0.9021
Epoch 10/10
6795/6795 [==============================] - 3s 485us/step - loss: 0.0839 - acc: 0.9678 - val_loss: 0.2941 - val_acc: 0.9034
training on pickle x_train_splitted2.pickle
Train on 6795 samples, validate on 756 samples
Epoch 1/10
6795/6795 [==============================] - 3s 477us/step - loss: 0.3070 - acc: 0.8898 - val_loss: 0.4061 - val_acc: 0.8466
Epoch 2/10
6795/6795 [==============================] - 3s 488us/step - loss: 0.2366 - acc: 0.9051 - val_loss: 0.3811 - val_acc: 0.8598
Epoch 3/10
6795/6795 [==============================] - 3s 488us/step - loss: 0.1837 - acc: 0.9266 - val_loss: 0.3025 - val_acc: 0.8783
Epoch 4/10
6795/6795 [==============================] - 3s 472us/step - loss: 0.1502 - acc: 0.9422 - val_loss: 0.2781 - val_acc: 0.8981
Epoch 5/10
6795/6795 [==============================] - 3s 478us/step - loss: 0.1336 - acc: 0.9460 - val_loss: 0.2979 - val_acc: 0.8968
Epoch 6/10
6795/6795 [==============================] - 3s 482us/step - loss: 0.1114 - acc: 0.9550 - val_loss: 0.2540 - val_acc: 0.9101
Epoch 7/10
6795/6795 [==============================] - 3s 476us/step - loss: 0.0990 - acc: 0.9619 - val_loss: 0.2710 - val_acc: 0.9101
Epoch 8/10
6795/6795 [==============================] - 3s 470us/step - loss: 0.0825 - acc: 0.9673 - val_loss: 0.2677 - val_acc: 0.9008
Epoch 9/10
6795/6795 [==============================] - 3s 478us/step - loss: 0.0757 - acc: 0.9714 - val_loss: 0.3011 - val_acc: 0.9034
Epoch 10/10
6795/6795 [==============================] - 3s 485us/step - loss: 0.0597 - acc: 0.9773 - val_loss: 0.3461 - val_acc: 0.8876
training on pickle x_train_splitted3.pickle
Train on 6795 samples, validate on 755 samples
Epoch 1/10
6795/6795 [==============================] - 3s 474us/step - loss: 0.3008 - acc: 0.8987 - val_loss: 0.3063 - val_acc: 0.8914
Epoch 2/10
6795/6795 [==============================] - 3s 469us/step - loss: 0.2187 - acc: 0.9186 - val_loss: 0.2681 - val_acc: 0.9060
Epoch 3/10
6795/6795 [==============================] - 3s 472us/step - loss: 0.1546 - acc: 0.9394 - val_loss: 0.2933 - val_acc: 0.8808
Epoch 4/10
6795/6795 [==============================] - 3s 479us/step - loss: 0.1418 - acc: 0.9429 - val_loss: 0.2066 - val_acc: 0.9232
Epoch 5/10
6795/6795 [==============================] - 3s 472us/step - loss: 0.1151 - acc: 0.9539 - val_loss: 0.2456 - val_acc: 0.9245
Epoch 6/10
6795/6795 [==============================] - 3s 479us/step - loss: 0.0982 - acc: 0.9617 - val_loss: 0.2167 - val_acc: 0.9113
Epoch 7/10
6795/6795 [==============================] - 3s 489us/step - loss: 0.0788 - acc: 0.9710 - val_loss: 0.2827 - val_acc: 0.8980
Epoch 8/10
6795/6795 [==============================] - 3s 498us/step - loss: 0.0722 - acc: 0.9723 - val_loss: 0.2314 - val_acc: 0.9285
Epoch 9/10
6795/6795 [==============================] - 3s 498us/step - loss: 0.0623 - acc: 0.9762 - val_loss: 0.2198 - val_acc: 0.9351
Epoch 10/10
6795/6795 [==============================] - 3s 487us/step - loss: 0.0623 - acc: 0.9772 - val_loss: 0.2512 - val_acc: 0.9152
training on pickle x_train_splitted4.pickle
Train on 6795 samples, validate on 755 samples
Epoch 1/10
6795/6795 [==============================] - 3s 487us/step - loss: 0.2633 - acc: 0.9142 - val_loss: 0.1740 - val_acc: 0.9338
Epoch 2/10
6795/6795 [==============================] - 3s 486us/step - loss: 0.1956 - acc: 0.9274 - val_loss: 0.2020 - val_acc: 0.9232
Epoch 3/10
6795/6795 [==============================] - 3s 480us/step - loss: 0.1372 - acc: 0.9470 - val_loss: 0.1937 - val_acc: 0.9311
Epoch 4/10
6795/6795 [==============================] - 3s 483us/step - loss: 0.1178 - acc: 0.9529 - val_loss: 0.1570 - val_acc: 0.9391
Epoch 5/10
6795/6795 [==============================] - 3s 489us/step - loss: 0.0989 - acc: 0.9611 - val_loss: 0.1346 - val_acc: 0.9523
Epoch 6/10
6795/6795 [==============================] - 3s 492us/step - loss: 0.0740 - acc: 0.9728 - val_loss: 0.1892 - val_acc: 0.9430
Epoch 7/10
6795/6795 [==============================] - 3s 479us/step - loss: 0.0782 - acc: 0.9688 - val_loss: 0.2161 - val_acc: 0.9298
Epoch 8/10
6795/6795 [==============================] - 3s 474us/step - loss: 0.0663 - acc: 0.9740 - val_loss: 0.1850 - val_acc: 0.9417
Epoch 9/10
6795/6795 [==============================] - 3s 476us/step - loss: 0.0540 - acc: 0.9788 - val_loss: 0.2376 - val_acc: 0.9258
Epoch 10/10
6795/6795 [==============================] - 3s 477us/step - loss: 0.0504 - acc: 0.9812 - val_loss: 0.1717 - val_acc: 0.9457